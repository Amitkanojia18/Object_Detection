import cv2
import os
from yolov5.models.common import DetectMultiBackend
import torch  

# Load the YOLOv5 model
model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)


def detect_and_label(frame):
    results = model(frame)

    # Extract boundary boxes, labels, confidence score to predict
    labels, confidences, boxes = results.xyxyn[0][:, -1], results.xyxyn[0][:, -2], results.xyxyn[0][:, :-2]

   
    scaling_factor = 0.8  # 80% of the original size

    for box, label, confidence in zip(boxes, labels, confidences):
        if confidence > 0.5:  # threshold
            x1, y1, x2, y2 = int(box[0] * frame.shape[1]), int(box[1] * frame.shape[0]), int(
                box[2] * frame.shape[1]), int(box[3] * frame.shape[0])
            class_name = model.names[int(label)]

            width = x2 - x1
            height = y2 - y1
            x1 = int(x1 + (width * (1 - scaling_factor)) / 2)
            y1 = int(y1 + (height * (1 - scaling_factor)) / 2)
            x2 = int(x2 - (width * (1 - scaling_factor)) / 2)
            y2 = int(y2 - (height * (1 - scaling_factor)) / 2)

            # Classifying whether the person is an adult or child
            if class_name == 'person':
                if (y2 - y1) < frame.shape[0] / 2:
                    label = 'Child'
                else:
                    label = 'Adult'

                # Outlines
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f'{label} {confidence:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9,
                            (255, 0, 0), 2)

    return frame

# Path to the folder where videos are stored
VIDEO_DIR = 'videos/'

video_name = input("Enter the full name of the video file (e.g., video_1.mp4): ")

video_path = os.path.join(VIDEO_DIR, video_name)

# Check if the file exists
if not os.path.exists(video_path):
    print(f"Error: {video_name} not found in {VIDEO_DIR}")
    exit(1)

video_capture = cv2.VideoCapture(video_path)


while video_capture.isOpened():
    ret, frame = video_capture.read()

    if not ret:
        break

    labeled_frame = detect_and_label(frame)

    cv2.imshow('Video', labeled_frame)

    # Press 'q' to quit the video early
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

video_capture.release()
cv2.destroyAllWindows()
